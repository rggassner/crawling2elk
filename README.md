# ğŸ•·ï¸ Smart Crawler with NSFW Detection, Elasticsearch Integration & Link Intelligence

This is a modular, scalable web crawling framework built for advanced scraping, data enrichment, and media classification. It features built-in support for:

-   âœ… Open directory detection
    
-   ğŸ” Advanced URL pattern handling and filtering
    
-   ğŸ§  NSFW content detection using `opennsfw2`
    
-   ğŸ§± Elasticsearch integration for scalable storage and analysis
    
-   ğŸ¦¾ Selenium with stealth via `selenium-wire` and `fake-useragent`
    
-   ğŸ§  Word extraction for keyword indexing
    
-   ğŸ”— Email harvesting
    
-   ğŸ“‚ URL de-duplication, allow/block listing, and intelligent path handling
    

* * *

## ğŸš€ Features

-   **Smart link discovery** â€“ supports relative/absolute URL normalization and classification.
    
-   **Open Directory Detection** â€“ detects classic index pages.
    
-   **NSFW Classifier** â€“ classifies images using `opennsfw2` model.
    
-   **Email Scraper** â€“ detects and stores emails.
    
-   **Elasticsearch-backed** â€“ stores and updates URL metadata, deduplicated using a SHA-256 hash.
    
-   **Pluggable Architecture** â€“ easily extend with new URL handlers using decorators.
    
-   **Error-tolerant** â€“ many defensive checks for robustness.
    
-   **Configurable via `config.py`** â€“ fully customizable logic and thresholds.
    

* * *

## ğŸ§± Requirements

Youâ€™ll need the following installed:

-   `sudo apt install python3-pip`
  
-   `sudo apt install expect`
  
-   `sudo apt install chromium-chromedriver`

Install dependencies:

`pip install -r requirements.txt`

Main external libraries used:

-   `selenium-wire`
    
-   `opennsfw2`
    
-   `fake-useragent`
    
-   `beautifulsoup4`
    
-   `Pillow`
    
-   `elasticsearch`
    
-   `numpy`
    

* * *

## ğŸ› ï¸ Configuration

All tunables live in `config.py`:

-   Allow/block regex patterns
    
-   Word processing settings (`WORDS_TO_LOWER`, etc.)
    
-   Elasticsearch connection info
    
-   Custom URL handler regex
    

* * *

## ğŸ“š Function Highlights

-   `db_insert_if_new_url()` â€“ inserts URL if new or updates with `visited`, NSFW status, resolution, etc.
    
-   `db_update_url()` â€“ updates metadata of visited URLs.
    
-   `get_words()` â€“ extracts clean keywords from soup or text.
    
-   `get_links()` â€“ extracts links and dispatches to appropriate handlers.
    
-   `get_directory_tree()` â€“ builds a tree of parent paths from a URL.
    
-   `get_url_function()` â€“ decorator that registers functions to handle URL regexes.
    

* * *

## ğŸ§© Extending the Engine

Add your own URL handler like this:


`@function_for_url([r"your-regex-here"]) def custom_handler(args):     # your logic     return True`

This makes the engine modular and powerful for specialized scraping and analysis tasks.

* * *

## ğŸ”’ Notes

-   URLs are hashed with SHA-256 to use as Elasticsearch document IDs.
    
-   Avoid scanning with identifiable fingerprints: user agents are randomized.
    
-   Warnings are suppressed to reduce noise, but can be enabled for debugging.
    
* * *

## ğŸ’¬ Author Notes

Built for performance, flexibility, and stealth. Use responsibly.

